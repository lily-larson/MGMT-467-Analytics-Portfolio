{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lily-larson/MGMT-467-Analytics-Portfolio/blob/main/Labs/Lab_2_VertexAI_BigQuery_PromptsOnly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecd5d16",
      "metadata": {
        "id": "4ecd5d16"
      },
      "source": [
        "# Lab: Vertex AI–Assisted BigQuery Analytics — Example Prompts\n",
        "**Goal:** Practice moving from simple SQL to complex analytics in BigQuery using *only* carefully engineered prompts with Vertex AI (Gemini).  \n",
        "**Important:** This notebook contains **prompts only** (no starter code). Paste the prompts into **Vertex AI Studio**, **Vertex AI in Colab Enterprise**, or your chosen chat interface, and then run the generated SQL directly in **BigQuery**. If you decide to automate later, you can ask Vertex AI to convert the winning SQL into a Colab pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a8d5cd",
      "metadata": {
        "id": "b8a8d5cd"
      },
      "source": [
        "## How to use this prompts-only notebook\n",
        "1. Open **Vertex AI Studio** (or Gemini in Colab Enterprise chat panel).  \n",
        "2. Copy a prompt from this notebook and paste it into the model. Do **not** paste any code from here; let the model generate it.  \n",
        "3. Run the generated SQL in **BigQuery** (Console → BigQuery Studio).  \n",
        "4. Iterate: refine the prompt when results aren’t what you expect.  \n",
        "5. Document: capture your final SQL, plus a one-sentence takeaway, in your notes/README."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e967d4a7",
      "metadata": {
        "id": "e967d4a7"
      },
      "source": [
        "## Dataset assumptions\n",
        "Use one of these sources (adjust table paths accordingly):\n",
        "- **Global Superstore (Kaggle)** loaded into BigQuery (e.g., `[YOUR_PROJECT].superstore_data.sales`)  \n",
        "- **TheLook eCommerce** public dataset: `bigquery-public-data.thelook_ecommerce`  \n",
        "If you are using *Global Superstore*, make sure column names match your schema (e.g., `Order_Date`, `Region`, `Category`, `Sub_Category`, `Sales`, `Profit`, `Discount`, `State`, `Customer_ID`, `Ship_Mode`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5940720",
      "metadata": {
        "id": "f5940720"
      },
      "source": [
        "---\n",
        "## Prompting guardrails (quick checklist)\n",
        "- **Be explicit**: table path, column names, filters, output columns, sort order, and limits.  \n",
        "- **Ask for runnable SQL**: “Return a BigQuery SQL block only.”  \n",
        "- **Control cost**: ask for `LIMIT` during exploration and remove it for the final run.  \n",
        "- **Validate**: request a brief explanation of why each clause is present and how you can sanity-check results.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "deGHQK9Tm7Rq"
      },
      "id": "deGHQK9Tm7Rq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Google Cloud BigQuery client library\n",
        "#!pip install google-cloud-bigquery==3.17.0 pandas==2.1.4\n",
        "\n",
        "# Authenticate your Colab environment\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "id": "C75yp0ekYtNl"
      },
      "id": "C75yp0ekYtNl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy Schema to a dataframe"
      ],
      "metadata": {
        "id": "jxAyMbWZnEe0"
      },
      "id": "jxAyMbWZnEe0"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your Google Cloud Project ID\n",
        "project_id = 'directed-bongo-471119-d1' # This is derived from your provided table name\n",
        "dataset_id = 'lab1_helpme'\n",
        "table_id = 'Global Superstore Sample Lab 1'\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Get the table object\n",
        "table_ref = client.dataset(dataset_id).table(table_id)\n",
        "table = client.get_table(table_ref)\n",
        "\n",
        "# Extract schema information\n",
        "schema_list = []\n",
        "for field in table.schema:\n",
        "    schema_list.append({\n",
        "        'name': field.name,\n",
        "        'field_type': field.field_type,\n",
        "        'mode': field.mode,\n",
        "        'description': field.description\n",
        "    })\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "schema_df = pd.DataFrame(schema_list)\n",
        "\n",
        "# Display the schema DataFrame (optional, for verification)\n",
        "print(\"Schema DataFrame created:\", schema_df)\n",
        "# To see the output, run the code.\n"
      ],
      "metadata": {
        "id": "Pdp4EpOIY93w",
        "collapsed": true
      },
      "id": "Pdp4EpOIY93w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLean Column Names"
      ],
      "metadata": {
        "id": "QkdVGvHZnNNn"
      },
      "id": "QkdVGvHZnNNn"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Clean the Column Names ---\n",
        "# Create a 'clean_name' column with standard naming conventions:\n",
        "# lowercase, with spaces and hyphens replaced by underscores.\n",
        "schema_df['clean_name'] = schema_df['name'].str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
        "\n",
        "\n",
        "# --- 2. Generate the Aliases for the SELECT Clause ---\n",
        "column_expressions = []\n",
        "for index, row in schema_df.iterrows():\n",
        "    original_name = row['name']\n",
        "    clean_name = row['clean_name']\n",
        "\n",
        "    # If the original name contains a space or special character, it needs to be\n",
        "    # enclosed in backticks (`) in the SQL statement.\n",
        "    if ' ' in original_name or '-' in original_name:\n",
        "        expression = f'`{original_name}` AS {clean_name}'\n",
        "    else:\n",
        "        # If the name is already clean, we still alias it for consistency.\n",
        "        expression = f'{original_name} AS {clean_name}'\n",
        "    column_expressions.append(expression)\n",
        "\n",
        "# Join all the individual column expressions into a single, formatted string.\n",
        "select_clause = \",\\n  \".join(column_expressions)\n",
        "\n",
        "\n",
        "# --- 3. Construct the Final CREATE VIEW Statement ---\n",
        "new_view_id = 'global_superstore_sample_clean' # You can change this if you like\n",
        "\n",
        "create_view_sql = f\"\"\"\n",
        "CREATE OR REPLACE VIEW `{project_id}.{dataset_id}.{new_view_id}` AS\n",
        "SELECT\n",
        "  {select_clause}\n",
        "FROM\n",
        "  `{project_id}.{dataset_id}.{table_id}`;\n",
        "\"\"\"\n",
        "\n",
        "# --- 4. Print the Final SQL ---\n",
        "print(\"--- Copy the SQL below and run it in your BigQuery Console ---\")\n",
        "print(create_view_sql)"
      ],
      "metadata": {
        "id": "hjxWwOPYgyu3"
      },
      "id": "hjxWwOPYgyu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate View with standard column naming convention"
      ],
      "metadata": {
        "id": "Av6ZsQoIhw7v"
      },
      "id": "Av6ZsQoIhw7v"
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the CREATE VIEW SQL query\n",
        "try:\n",
        "    query_job = client.query(create_view_sql)  # API request\n",
        "    query_job.result()  # Waits for the query to finish\n",
        "    print(f\"View '{new_view_id}' created/replaced successfully in dataset '{dataset_id}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while creating the view: {e}\")\n",
        "\n",
        "# Now, let's print 10 rows from the newly created view to verify\n",
        "print(f\"\\n--- First 10 rows from the new view '{new_view_id}' ---\")\n",
        "try:\n",
        "    # Construct a reference to the new view\n",
        "    view_query = f\"SELECT * FROM `{project_id}.{dataset_id}.{new_view_id}` LIMIT 10\"\n",
        "\n",
        "    # Execute the query\n",
        "    query_job = client.query(view_query)\n",
        "\n",
        "    # Fetch the results into a DataFrame\n",
        "    rows_df = query_job.to_dataframe()\n",
        "\n",
        "    # Print the DataFrame\n",
        "    display(rows_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while fetching rows from the view: {e}\")"
      ],
      "metadata": {
        "id": "xoMmfxY2hOOg"
      },
      "id": "xoMmfxY2hOOg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This assumes your 'client' object from the previous cell is still active\n",
        "# and correctly authenticated.\n",
        "\n",
        "print(\"✅ Step 1: Defining the query string...\")\n",
        "\n",
        "query_string = \"\"\"\n",
        "SELECT\n",
        "  order_id,\n",
        "  customer_name,\n",
        "  product_name,\n",
        "  sales,\n",
        "  profit\n",
        "FROM\n",
        "  `mgmt-467-47888.lab1_foundation.superstore_clean`\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "print(\"✅ Step 2: Sending the query to BigQuery. This may take a moment...\")\n",
        "\n",
        "# Use a try-except block to catch potential errors\n",
        "try:\n",
        "    query_job = client.query(query_string)\n",
        "\n",
        "    print(\"✅ Step 3: Waiting for query to complete and fetching results...\")\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    print(f\"✅ Step 4: Query finished. Found {len(results_df)} rows.\")\n",
        "\n",
        "    if results_df.empty:\n",
        "        print(\"\\n⚠️ The query ran successfully but returned an empty result. Please double-check that your 'superstore_clean' view exists and the original table has data.\")\n",
        "    else:\n",
        "        print(\"\\n--- Displaying Results ---\")\n",
        "        display(results_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "BDjVOddXjBvS"
      },
      "id": "BDjVOddXjBvS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-aQV1fUlLsh"
      },
      "id": "I-aQV1fUlLsh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vpNaruc0gxgO"
      },
      "id": "vpNaruc0gxgO"
    },
    {
      "cell_type": "markdown",
      "id": "21fdd1b4",
      "metadata": {
        "id": "21fdd1b4"
      },
      "source": [
        "## Part A — SQL Warm‑Up (SELECT, WHERE, ORDER BY, LIMIT, DISTINCT)\n",
        "**Aim:** Build confidence with precise, unambiguous prompts that yield clean, runnable SQL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51345cd",
      "metadata": {
        "id": "d51345cd"
      },
      "source": [
        "### A1. Unique values (DISTINCT)\n",
        "**Prompt (paste in Vertex AI):**\n",
        "```\n",
        "Act as a senior BigQuery analyst. Produce a **single runnable BigQuery SQL** (no commentary) for:\n",
        "- Task: List all unique `Sub_Category` values sold in the 'West' region.\n",
        "- Table: `mgmt-467-47888.lab1_foundation.superstore`\n",
        "- Filter: `Region = 'West'`\n",
        "- Output: a single column named `Sub_Category`\n",
        "- Sort: alphabetically A→Z\n",
        "- Add: `LIMIT 100` to control cost during exploration.\n",
        "```\n",
        "**Reflection:** Did the result match your expectations? If not, what ambiguity in your prompt might have caused the mismatch?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "    DISTINCT `Sub-Category` AS Sub_Category\n",
        "FROM\n",
        "    `mgmt-467-47888.lab1_foundation.superstore_clean`\n",
        "WHERE\n",
        "    Region = 'West'\n",
        "ORDER BY\n",
        "    Sub_Category ASC\n",
        "LIMIT 100\n",
        "\"\"\"\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "FIjfmUFEiMA4"
      },
      "id": "FIjfmUFEiMA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d6d69d23",
      "metadata": {
        "id": "d6d69d23"
      },
      "source": [
        "### A2. Top‑N by metric (ORDER BY … DESC)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Return the top 10 customers by total profit.\n",
        "Table: `mgmt-467-47888.lab_foundation.superstore`\n",
        "Columns used: `Customer_ID`, `Profit`\n",
        "Output columns: `Customer_ID`, `total_profit`\n",
        "Logic: SUM Profit per customer, order by `total_profit` DESC\n",
        "Add `LIMIT 10`.\n",
        "```\n",
        "**Tip:** If your schema uses different identifiers (e.g., `Customer Name`), restate column names explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "55838b8c"
      },
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "    customer_id,\n",
        "    SUM(profit) AS total_profit\n",
        "FROM\n",
        "    `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "GROUP BY\n",
        "    customer_id\n",
        "ORDER BY\n",
        "    total_profit DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "print(\"✅ Step 1: Defining the query string...\")\n",
        "print(query_string)\n",
        "\n",
        "print(\"✅ Step 2: Sending the query to BigQuery. This may take a moment...\")\n",
        "\n",
        "# Use a try-except block to catch potential errors\n",
        "try:\n",
        "    query_job = client.query(query_string)\n",
        "\n",
        "    print(\"✅ Step 3: Waiting for query to complete and fetching results...\")\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    print(f\"✅ Step 4: Query finished. Found {len(results_df)} rows.\")\n",
        "\n",
        "    if results_df.empty:\n",
        "        print(\"\\n⚠️ The query ran successfully but returned an empty result.\")\n",
        "    else:\n",
        "        print(\"\\n--- Displaying Results ---\")\n",
        "        display(results_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ An error occurred: {e}\")"
      ],
      "id": "55838b8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f4a477d4",
      "metadata": {
        "id": "f4a477d4"
      },
      "source": [
        "### A3. Basic filtering (WHERE) + sanity checks\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Count orders shipped with each `Ship_Mode`, but only for orders in the 'Technology' category.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Output: `Ship_Mode`, `order_count`\n",
        "Logic: COUNT(*) grouped by `Ship_Mode`\n",
        "Sort by `order_count` DESC\n",
        "```\n",
        "**Validation ask:** “Also list two quick sanity checks to verify the numbers.”"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "SELECT\n",
        "    ship_mode,\n",
        "    COUNT(*) AS order_count\n",
        "FROM\n",
        "    `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "WHERE\n",
        "    category = 'Technology'\n",
        "GROUP BY\n",
        "    ship_mode\n",
        "ORDER BY\n",
        "    order_count DESC"
      ],
      "metadata": {
        "id": "NqPYyIcNqVXk"
      },
      "id": "NqPYyIcNqVXk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c603c08"
      },
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "SELECT\n",
        "    COUNT(*) AS total_technology_orders\n",
        "FROM\n",
        "    `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "WHERE\n",
        "    category = 'Technology'"
      ],
      "id": "8c603c08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43fc6dd2"
      },
      "source": [
        "**Sanity Checks:**\n",
        "1. **Sum of `order_count`:** The sum of the `order_count` for all ship modes equals the total number of orders in the dataset where the `category` is 'Technology'.\n",
        "2. **Check for other categories:** Verified that the query is filtering for 'Technology' by running the query without the `WHERE category = 'Technology'`. The sum of counts in the original query was less than the total count without the filter."
      ],
      "id": "43fc6dd2"
    },
    {
      "cell_type": "markdown",
      "id": "51afdc05",
      "metadata": {
        "id": "51afdc05"
      },
      "source": [
        "## Part B — Grouped Analytics (GROUP BY, HAVING)\n",
        "**Aim:** Turn raw facts into grouped metrics and filtered aggregations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c5933e",
      "metadata": {
        "id": "10c5933e"
      },
      "source": [
        "### B1. KPI aggregation with WHERE + GROUP BY\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Compute monthly revenue for the last 12 full months.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Assume: `Order_Date` is a DATE or TIMESTAMP column named exactly `Order_Date`.\n",
        "Output: `year_month` (YYYY-MM format), `monthly_revenue`\n",
        "Logic: Truncate date to month, SUM `Sales`, filter to last 12 full months.\n",
        "Sort by `year_month` ascending.\n",
        "Include a `LIMIT` safeguard for exploration.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your Google Cloud Project ID\n",
        "project_id = 'directed-bongo-471119-d1' # This is derived from your provided table name\n",
        "dataset_id = 'lab1_helpme'\n",
        "table_id = 'global_superstore_sample_clean'\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)"
      ],
      "metadata": {
        "id": "9u9tjg0JsZA8"
      },
      "id": "9u9tjg0JsZA8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SQL query\n",
        "%%bigquery --project directed-bongo-471119-d1\n",
        "SELECT\n",
        "    FORMAT_DATE('%Y-%m', DATE_TRUNC(order_date, MONTH)) AS year_month,\n",
        "    SUM(sales) AS monthly_revenue\n",
        "FROM\n",
        "    `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "WHERE\n",
        "    order_date >= DATE_TRUNC((SELECT MAX(order_date)FROM `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`), MONTH) - INTERVAL 11 MONTH\n",
        "GROUP BY\n",
        "    year_month\n",
        "ORDER BY\n",
        "    year_month ASC\n",
        "LIMIT 100; -- Added LIMIT for exploration as requested"
      ],
      "metadata": {
        "id": "sjlnleuBrpBF"
      },
      "id": "sjlnleuBrpBF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "15d75d03",
      "metadata": {
        "id": "15d75d03"
      },
      "source": [
        "### B2. Post‑aggregation filter (HAVING)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Find sub-categories whose total profit over the entire dataset is negative.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Output: `Sub_Category`, `total_profit`\n",
        "Logic: SUM `Profit` GROUP BY `Sub_Category`, HAVING SUM(Profit) < 0\n",
        "Sort by `total_profit` ASC (most negative first).\n",
        "```\n",
        "**Why HAVING?** Ask the model to include a 1-sentence explanation of why HAVING is used instead of WHERE here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "SELECT\n",
        "    sub_category,\n",
        "    SUM(profit) AS total_profit\n",
        "FROM\n",
        "    `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "GROUP BY\n",
        "    sub_category\n",
        "HAVING\n",
        "    SUM(profit) < 0\n",
        "ORDER BY\n",
        "    total_profit ASC"
      ],
      "metadata": {
        "id": "l44xmPvNwVqs"
      },
      "id": "l44xmPvNwVqs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HAVING is used instead of WHERE because it filters results based on the output of an aggregate function (SUM(profit)), which WHERE cannot do."
      ],
      "metadata": {
        "id": "R9wFPRWXxUA-"
      },
      "id": "R9wFPRWXxUA-"
    },
    {
      "cell_type": "markdown",
      "id": "bbd28071",
      "metadata": {
        "id": "bbd28071"
      },
      "source": [
        "## Part C — Joins (dimension enrichment)\n",
        "**Aim:** Use joins to enhance facts with attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7736534",
      "metadata": {
        "id": "e7736534"
      },
      "source": [
        "### C1. Join facts to a small dimension\n",
        "*(If you have a customer or product dimension in your schema, use it. Otherwise, request a synthetic example.)*  \n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Join the sales table to a product dimension to report `Product_ID`, `Product_Name`, and total sales.\n",
        "Tables: `[YOUR_PROJECT].superstore_data.sales` as s, `[YOUR_PROJECT].superstore_data.products` as p\n",
        "Join key: `s.Product_ID = p.Product_ID`\n",
        "Output: `Product_ID`, `Product_Name`, `total_sales`\n",
        "Sort by `total_sales` DESC\n",
        "```\n",
        "**If you lack a dimension table:** Ask the model how to simulate one temporarily via a CTE."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1"
      ],
      "metadata": {
        "id": "QsKmcZ4uxZto"
      },
      "id": "QsKmcZ4uxZto",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dca07c5a",
      "metadata": {
        "id": "dca07c5a"
      },
      "source": [
        "## Part D — Common Table Expressions (CTEs)\n",
        "**Aim:** Make complex logic readable and testable in steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b268567f",
      "metadata": {
        "id": "b268567f"
      },
      "source": [
        "### D1. Multi‑step ranking with CTEs\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Goal: Within each `Region`, rank states by total sales and return top 3 per region.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE 1 (`state_sales`): SUM(Sales) by `Region`, `State`\n",
        "CTE 2 (`ranked_state_sales`): Add `RANK() OVER (PARTITION BY Region ORDER BY total_sales DESC)` as `sales_rank`\n",
        "Final SELECT: rows where `sales_rank <= 3`\n",
        "Output columns: `Region`, `State`, `total_sales`, `sales_rank`\n",
        "Sort: by `Region`, then `sales_rank`\n",
        "```\n",
        "**Ask for**: a one-paragraph explanation of each step, then **provide only the final runnable SQL**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "\n",
        "WITH state_sales AS (\n",
        "    SELECT\n",
        "        region,\n",
        "        state,\n",
        "        SUM(sales) AS total_sales\n",
        "    FROM\n",
        "        `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "    GROUP BY\n",
        "        region,\n",
        "        state\n",
        "),\n",
        "ranked_state_sales AS (\n",
        "    SELECT\n",
        "        region,\n",
        "        state,\n",
        "        total_sales,\n",
        "        RANK() OVER (PARTITION BY region ORDER BY total_sales DESC) AS sales_rank\n",
        "    FROM\n",
        "        state_sales\n",
        ")\n",
        "SELECT\n",
        "    region,\n",
        "    state,\n",
        "    total_sales,\n",
        "    sales_rank\n",
        "FROM\n",
        "    ranked_state_sales\n",
        "WHERE\n",
        "    sales_rank <= 3\n",
        "ORDER BY\n",
        "    region,\n",
        "    sales_rank"
      ],
      "metadata": {
        "id": "xwlN6EeH0vgf"
      },
      "id": "xwlN6EeH0vgf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "46a39db5",
      "metadata": {
        "id": "46a39db5"
      },
      "source": [
        "### D2. Time‑boxed “most improved” analysis\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Goal: Identify the top 5 sub-categories with the largest YoY revenue increase from 2023 to 2024.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE `yr_sales`: SUM(Sales) by `Sub_Category` and `year` extracted from `Order_Date`\n",
        "Final: pivot or self-join to compute delta (2024 minus 2023) as `yoy_delta`\n",
        "Output: `Sub_Category`, `sales_2023`, `sales_2024`, `yoy_delta`\n",
        "Order by `yoy_delta` DESC\n",
        "Limit 5\n",
        "```\n",
        "**Validation:** Ask the model for two quick failure modes (e.g., missing years) and how to handle them."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "\n",
        "WITH yearly_sales AS (\n",
        "    SELECT\n",
        "        sub_category,\n",
        "        EXTRACT(YEAR FROM order_date) AS sales_year,\n",
        "        SUM(sales) AS yearly_revenue\n",
        "    FROM\n",
        "        `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "    GROUP BY\n",
        "        sub_category,\n",
        "        sales_year\n",
        "),\n",
        "ranked_yearly_sales AS (\n",
        "    SELECT\n",
        "        sub_category,\n",
        "        sales_year,\n",
        "        yearly_revenue,\n",
        "        RANK() OVER (PARTITION BY sub_category ORDER BY sales_year DESC) as year_rank\n",
        "    FROM yearly_sales\n",
        "),\n",
        "pivoted_sales AS (\n",
        "    SELECT\n",
        "        sub_category,\n",
        "        MAX(CASE WHEN year_rank = 1 THEN yearly_revenue ELSE NULL END) AS sales_most_recent_year,\n",
        "        MAX(CASE WHEN year_rank = 2 THEN yearly_revenue ELSE NULL END) AS sales_second_most_recent_year\n",
        "    FROM ranked_yearly_sales\n",
        "    WHERE year_rank <= 2\n",
        "    GROUP BY sub_category\n",
        ")\n",
        "SELECT\n",
        "    sub_category,\n",
        "    sales_second_most_recent_year AS sales_year_1,\n",
        "    sales_most_recent_year AS sales_year_2,\n",
        "    (sales_most_recent_year - sales_second_most_recent_year) AS change\n",
        "FROM pivoted_sales\n",
        "WHERE sales_second_most_recent_year IS NOT NULL AND sales_most_recent_year IS NOT NULL\n",
        "ORDER BY change DESC\n",
        "LIMIT 5;"
      ],
      "metadata": {
        "id": "H5jwMfhl3b1a"
      },
      "id": "H5jwMfhl3b1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c776dd89",
      "metadata": {
        "id": "c776dd89"
      },
      "source": [
        "## Part E — Window Functions (ROW_NUMBER, RANK, DENSE_RANK, LAG/LEAD, moving averages)\n",
        "**Aim:** Compare rows across partitions and time; compute trends and ranks without collapsing rows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a5cf0c4",
      "metadata": {
        "id": "6a5cf0c4"
      },
      "source": [
        "### E1. Top product per region (ROW_NUMBER)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: For each `Region`, return only the single highest-revenue `Sub_Category`.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE `subcat_sales`: SUM(Sales) by `Region`, `Sub_Category`\n",
        "Add `ROW_NUMBER() OVER (PARTITION BY Region ORDER BY total_sales DESC)` as rn\n",
        "Final: filter `rn = 1`\n",
        "Output: `Region`, `Sub_Category`, `total_sales`\n",
        "Sort by `Region`\n",
        "```\n",
        "**Why `ROW_NUMBER` instead of `RANK`?** Ask the model to add a 2-sentence contrast."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "\n",
        "WITH subcat_sales AS (\n",
        "    SELECT\n",
        "        region,\n",
        "        sub_category,\n",
        "        SUM(sales) AS total_sales\n",
        "    FROM\n",
        "        `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "    GROUP BY\n",
        "        region,\n",
        "        sub_category\n",
        "),\n",
        "ranked_subcat_sales AS (\n",
        "    SELECT\n",
        "        region,\n",
        "        sub_category,\n",
        "        total_sales,\n",
        "        ROW_NUMBER() OVER (PARTITION BY region ORDER BY total_sales DESC) AS rn\n",
        "    FROM\n",
        "        subcat_sales\n",
        ")\n",
        "SELECT\n",
        "    region,\n",
        "    sub_category,\n",
        "    total_sales\n",
        "FROM\n",
        "    ranked_subcat_sales\n",
        "WHERE\n",
        "    rn = 1\n",
        "ORDER BY\n",
        "    region"
      ],
      "metadata": {
        "id": "Wn8Q8NbRBQS2"
      },
      "id": "Wn8Q8NbRBQS2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROW_NUMBER() assigns a unique sequential integer to each row within its partition, even if there are ties in the ordering column. In contrast, RANK() assigns the same rank to rows with the same value in the ordering column, and then skips the subsequent rank numbers, which means you could get multiple rows with rank 1 if there's a tie, whereas ROW_NUMBER() would give them distinct numbers like 1, 2, 3, etc."
      ],
      "metadata": {
        "id": "-_U8arhWBpuP"
      },
      "id": "-_U8arhWBpuP"
    },
    {
      "cell_type": "markdown",
      "id": "552eb898",
      "metadata": {
        "id": "552eb898"
      },
      "source": [
        "### E2. YoY growth with LAG\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Compute year-over-year revenue growth for 'Phones' sub-category.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Steps:\n",
        "- Filter to `Sub_Category = 'Phones'`\n",
        "- Aggregate yearly revenue using EXTRACT(YEAR FROM Order_Date)\n",
        "- Add `LAG(yearly_revenue) OVER (ORDER BY year)` as `prev_revenue`\n",
        "- Compute `yoy_pct = 100.0 * (yearly_revenue - prev_revenue) / prev_revenue`\n",
        "Output: `year`, `yearly_revenue`, `prev_revenue`, `yoy_pct`\n",
        "Sort by `year` ASC\n",
        "```\n",
        "**Ask for**: a guard against divide-by-zero or NULL previous year."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "\n",
        "WITH yearly_phone_sales AS (\n",
        "    SELECT\n",
        "        EXTRACT(YEAR FROM order_date) AS sales_year,\n",
        "        SUM(sales) AS yearly_revenue\n",
        "    FROM\n",
        "        `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "    WHERE\n",
        "        sub_category = 'Phones'\n",
        "    GROUP BY\n",
        "        sales_year\n",
        "),\n",
        "lagged_sales AS (\n",
        "    SELECT\n",
        "        sales_year,\n",
        "        yearly_revenue,\n",
        "        LAG(yearly_revenue) OVER (ORDER BY sales_year ASC) AS prev_revenue\n",
        "    FROM\n",
        "        yearly_phone_sales\n",
        ")\n",
        "SELECT\n",
        "    sales_year AS year,\n",
        "    yearly_revenue,\n",
        "    prev_revenue,\n",
        "    SAFE_DIVIDE((yearly_revenue - prev_revenue), prev_revenue) * 100.0 AS yoy_pct\n",
        "FROM\n",
        "    lagged_sales\n",
        "ORDER BY\n",
        "    year ASC"
      ],
      "metadata": {
        "id": "Dj1HJE03CSaI"
      },
      "id": "Dj1HJE03CSaI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ac0c3893",
      "metadata": {
        "id": "ac0c3893"
      },
      "source": [
        "### E3. 3‑month moving average (MA)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: For the 'Corporate' segment, compute a 3-month moving average of monthly revenue.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Steps:\n",
        "- Derive `month` via DATE_TRUNC(Order_Date, MONTH)\n",
        "- SUM(Sales) per `month`\n",
        "- Add `AVG(monthly_revenue) OVER (ORDER BY month ROWS BETWEEN 2 PRECEDING AND CURRENT ROW)` as `ma_3`\n",
        "Output: `month`, `monthly_revenue`, `ma_3`\n",
        "Sort by `month` ASC\n",
        "```\n",
        "**Tip:** Ask the model to include a 1‑line cost control note (e.g., restrict date range while iterating)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "\n",
        "WITH monthly_revenue AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(order_date, MONTH) AS month,\n",
        "    SUM(sales) AS monthly_revenue\n",
        "  FROM `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "  GROUP BY month\n",
        ")\n",
        "SELECT\n",
        "  FORMAT_DATE('%Y-%m', mr.month) AS month,\n",
        "  mr.monthly_revenue,\n",
        "  ROUND(\n",
        "    AVG(mr.monthly_revenue) OVER (\n",
        "      ORDER BY mr.month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ), 2\n",
        "  ) AS moving_avg_3m\n",
        "FROM monthly_revenue mr\n",
        "ORDER BY mr.month ASC\n"
      ],
      "metadata": {
        "id": "t-DGLc0tHHLf"
      },
      "id": "t-DGLc0tHHLf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a4e347a6",
      "metadata": {
        "id": "a4e347a6"
      },
      "source": [
        "## Part F — Debugging & Optimization Prompts\n",
        "**Aim:** Use the model as a rubber duck for error handling and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d80923",
      "metadata": {
        "id": "e5d80923"
      },
      "source": [
        "### F1. Explain the error, propose a fix\n",
        "**Prompt:**\n",
        "```\n",
        "I ran this BigQuery SQL and got an error:\n",
        "WITH monthly_revenue AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(order_date, MONTH) AS month,\n",
        "    SUM(sales) AS monthly_revenue\n",
        "  FROM `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "  GROUP BY month\n",
        ")\n",
        "SELECT\n",
        "  FORMAT_DATE('%Y-%m', month) AS month,\n",
        "  monthly_revenue,\n",
        "  ROUND(\n",
        "    AVG(monthly_revenue) OVER (\n",
        "      ORDER BY month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ), 2\n",
        "  ) AS moving_avg_3m\n",
        "FROM monthly_revenue\n",
        "ORDER BY month ASC;\n",
        "\n",
        "ERROR: 400 No matching signature for aggregate function AVG Argument types: STRUCT<month DATE, monthly_revenue FLOAT64> Signature: AVG(INT64) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type INT64 Signature: AVG(FLOAT64) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type FLOAT64 Signature: AVG(NUMERIC) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type NUMERIC Signature: AVG(BIGNUMERIC) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type BIGNUMERIC Signature: AVG(INTERVAL) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type INTERVAL at [12:5]; reason: invalidQuery, location: query, message: No matching signature for aggregate function AVG Argument types: STRUCT<month DATE, monthly_revenue FLOAT64> Signature: AVG(INT64) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type INT64 Signature: AVG(FLOAT64) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type FLOAT64 Signature: AVG(NUMERIC) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type NUMERIC Signature: AVG(BIGNUMERIC) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type BIGNUMERIC Signature: AVG(INTERVAL) Argument 1: Unable to coerce type STRUCT<month DATE, monthly_revenue FLOAT64> to expected type INTERVAL at [12:5]\n",
        "\n",
        "Act as a BigQuery trouble‑shooter.\n",
        "1) Identify the root cause.\n",
        "2) Propose the smallest possible fix.\n",
        "3) Suggest a quick sanity check query to verify the fix.\n",
        "Return only the corrected SQL and a 2‑sentence rationale.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "WITH monthly_revenue AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(order_date, MONTH) AS month,\n",
        "    SUM(sales) AS monthly_revenue\n",
        "  FROM `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "  GROUP BY month\n",
        ")\n",
        "SELECT\n",
        "  FORMAT_DATE('%Y-%m', mr.month) AS month,\n",
        "  mr.monthly_revenue,\n",
        "  ROUND(\n",
        "    AVG(mr.monthly_revenue) OVER (\n",
        "      ORDER BY mr.month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ), 2\n",
        "  ) AS moving_avg_3m\n",
        "FROM monthly_revenue mr\n",
        "ORDER BY mr.month ASC;\n",
        "\"\"\"\n",
        "#The problem comes up when BigQuery interprets the entire row (STRUCT) instead\n",
        "# of just the numeric column. The key fix was explicitly prefixing\n",
        "# mr.monthly_revenue inside the AVG() so BigQuery knows you mean the numeric\n",
        "# field, not the entire row."
      ],
      "metadata": {
        "id": "kXg4M0P-U4Gs"
      },
      "id": "kXg4M0P-U4Gs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "890814f8",
      "metadata": {
        "id": "890814f8"
      },
      "source": [
        "### F2. Reduce cost / improve speed\n",
        "**Prompt:**\n",
        "```\n",
        "Act as a BigQuery cost optimizer.\n",
        "Given this query (below), list 3 ways to reduce scanned bytes and improve performance without changing the business logic.\n",
        "\n",
        "WITH monthly_revenue AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(order_date, MONTH) AS month,\n",
        "    SUM(sales) AS monthly_revenue\n",
        "  FROM `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "  GROUP BY month\n",
        ")\n",
        "SELECT\n",
        "  FORMAT_DATE('%Y-%m', mr.month) AS month,\n",
        "  mr.monthly_revenue,\n",
        "  ROUND(\n",
        "    AVG(mr.monthly_revenue) OVER (\n",
        "      ORDER BY mr.month\n",
        "      ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "    ), 2\n",
        "  ) AS moving_avg_3m\n",
        "FROM monthly_revenue mr\n",
        "ORDER BY mr.month ASC\n",
        "\n",
        "Prioritize: partition filters, column pruning, pre-aggregations, and temporary results via CTEs.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply Partition Filters:**\n",
        "Currently, the query scans all rows in the base table. If you only need recent months or a specific range, filter by partition early.\n",
        "\n",
        "**Column Pruning:**\n",
        "The base table likely has many columns (customer, region, product, etc.). Since you only need order_date and sales, explicitly select only those columns in the CTE.\n",
        "\n",
        "**Use Pre-Aggregations or Temporary Results:**\n",
        "If you run this query often, you could store pre-aggregated monthly revenue in a materialized view or a separate summary table keyed by month. Then the query would only scan the pre-aggregated dataset (far smaller), instead of recalculating sums from raw order_date and sales each time."
      ],
      "metadata": {
        "id": "9W7OXZl6VQAp"
      },
      "id": "9W7OXZl6VQAp"
    },
    {
      "cell_type": "markdown",
      "id": "1f88a2f5",
      "metadata": {
        "id": "1f88a2f5"
      },
      "source": [
        "## Part G — Validation & Counter‑examples (DIVE: Validate)\n",
        "**Aim:** Avoid “first‑answer fallacy” by testing alternatives."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed05c0b",
      "metadata": {
        "id": "2ed05c0b"
      },
      "source": [
        "### G1. Ask for counter‑queries\n",
        "**Prompt:**\n",
        "```\n",
        "I concluded that 'Tables' is a high‑sales but negative‑profit sub-category due to high discounts.\n",
        "Create two alternative BigQuery SQL queries that could falsify or nuance this finding:\n",
        "- One that slices by region and time\n",
        "- One that controls for order priority or ship mode\n",
        "Return BigQuery SQL only, then a one-paragraph note on how to compare outcomes.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "421d4dde"
      },
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "\n",
        "-- Query 1: Slice by region and time\n",
        "SELECT\n",
        "    region,\n",
        "    FORMAT_DATE('%Y-%m', DATE_TRUNC(order_date, MONTH)) AS year_month,\n",
        "    SUM(sales) AS monthly_sales,\n",
        "    SUM(profit) AS monthly_profit,\n",
        "    AVG(discount) AS average_discount\n",
        "FROM\n",
        "    `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "WHERE\n",
        "    sub_category = 'Tables'\n",
        "GROUP BY\n",
        "    region,\n",
        "    year_month\n",
        "ORDER BY\n",
        "    region,\n",
        "    year_month;"
      ],
      "id": "421d4dde",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe4accb3"
      },
      "source": [
        "%%bigquery --project directed-bongo-471119-d1\n",
        "\n",
        "-- Query 2: Control for ship mode\n",
        "SELECT\n",
        "    ship_mode,\n",
        "    SUM(sales) AS total_sales,\n",
        "    SUM(profit) AS total_profit,\n",
        "    AVG(discount) AS average_discount\n",
        "FROM\n",
        "    `directed-bongo-471119-d1.lab1_helpme.global_superstore_sample_clean`\n",
        "WHERE\n",
        "    sub_category = 'Tables'\n",
        "GROUP BY\n",
        "    ship_mode\n",
        "ORDER BY\n",
        "    total_profit ASC;"
      ],
      "id": "fe4accb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5dbaa81"
      },
      "source": [
        "To compare outcomes: Run these two queries alongside your original query for 'Tables'.\n",
        "- **Query 1 (Region & Time):** Look for specific regions or time periods where 'Tables' might actually be profitable or have lower discounts. This would suggest the problem isn't universal and might be concentrated in certain markets or seasonal.\n",
        "- **Query 2 (Ship Mode):** See if certain ship modes are associated with significantly lower profits or higher discounts for 'Tables'. This could indicate logistical or pricing issues tied to how these large items are shipped.\n",
        "If either of these queries shows scenarios where 'Tables' is profitable or discounts aren't unusually high under specific conditions, it would nuance or potentially falsify the initial conclusion that high discounts are the *sole* or primary driver of negative profit across the board."
      ],
      "id": "b5dbaa81"
    },
    {
      "cell_type": "markdown",
      "id": "1e108a43",
      "metadata": {
        "id": "1e108a43"
      },
      "source": [
        "## Part H — Synthesis (DIVE: Extend)\n",
        "**Aim:** Turn analysis into business‑ready insights."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf2bac2",
      "metadata": {
        "id": "0bf2bac2"
      },
      "source": [
        "### H1. Executive‑style summary\n",
        "**Prompt:**\n",
        "```\n",
        "Act as a business strategist.\n",
        "Based on the following metrics/figures (briefly summarize your results here), write a 4-sentence executive summary:\n",
        "- 1 sentence: what changed and by how much\n",
        "- 1 sentence: why it likely changed (drivers)\n",
        "- 1 sentence: recommended action (who/what/when)\n",
        "- 1 sentence: metric to monitor next\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e68391cd"
      },
      "source": [
        "While overall trends show growth in some sub-categories like 'Phones' (with a 33.4% YOY increase in 2017), other sub-categories, like 'Tables', continue to show significant negative profit (-$17,725.48 total profit). This likely stems from a combination of factors, including high discounts,inefficient shipping, and regional performance issues. Product management  teams should investigate the 'Tables' sub-category, focusing on discount strategies and logistics in underperforming regions to improve profitability. They should monitor the profitability and average discount of 'Tables' by region and ship mode on a monthly basis to track the impact of any changes."
      ],
      "id": "e68391cd"
    },
    {
      "cell_type": "markdown",
      "id": "f3b5fdc9",
      "metadata": {
        "id": "f3b5fdc9"
      },
      "source": [
        "### H2. Convert final SQL into an automated job (optional)\n",
        "**Prompt (use only after your SQL is final):**\n",
        "```\n",
        "Convert my final BigQuery SQL into a Python script that can run as a scheduled job from Colab or Cloud Functions.\n",
        "Requirements:\n",
        "- Use python‑bigquery client\n",
        "- Parameterize date range\n",
        "- Write results to a destination table `[YOUR_PROJECT].analytics.outputs_kpi`\n",
        "- Add basic error handling & logging\n",
        "Return one complete runnable script.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0148a198",
      "metadata": {
        "id": "0148a198"
      },
      "source": [
        "---\n",
        "## Submission checklist\n",
        "- [ ] Kept prompts precise and reproducible  \n",
        "- [ ] Captured at least **one** CTE query and **one** window function query  \n",
        "- [ ] Documented **two** validation attempts (counter‑queries or alternate slice)  \n",
        "- [ ] Wrote a 4‑sentence executive summary based on results  \n",
        "- [ ] (Optional) Converted final query into a scheduled job\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QkdVGvHZnNNn",
        "Av6ZsQoIhw7v",
        "21fdd1b4",
        "51afdc05",
        "bbd28071",
        "dca07c5a",
        "c776dd89",
        "1f88a2f5",
        "1e108a43"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}